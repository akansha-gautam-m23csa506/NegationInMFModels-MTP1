{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import re\n",
    "import string\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict, Counter\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from PIL import Image\n",
    "import torch\n",
    "import tqdm\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "import spacy\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load MCQ Dataset - Caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COCO shape: (5914, 7)\n",
      "VOC 2007 shape: (5031, 7)\n",
      "MSR VTT shape: (1000, 7)\n",
      "Final Metadata shape: (11945, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>correct_answer</th>\n",
       "      <th>caption_0</th>\n",
       "      <th>caption_1</th>\n",
       "      <th>caption_2</th>\n",
       "      <th>caption_3</th>\n",
       "      <th>correct_answer_template</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/coco/images/val2017/000000397133.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>This image features a knife, but no car is present.</td>\n",
       "      <td>A car is present in this image, but there is no knife.</td>\n",
       "      <td>This image features a car</td>\n",
       "      <td>This image does not feature a knife.</td>\n",
       "      <td>hybrid</td>\n",
       "      <td>coco</td>\n",
       "      <td>000000397133.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/coco/images/val2017/000000397133.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>A chair is not present in this image.</td>\n",
       "      <td>This image shows a chair, but no spoon is present.</td>\n",
       "      <td>A chair is present in this image.</td>\n",
       "      <td>A spoon is not included in this image.</td>\n",
       "      <td>negative</td>\n",
       "      <td>coco</td>\n",
       "      <td>000000397133.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/coco/images/val2017/000000397133.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>A person is present in this image, but there's no fork.</td>\n",
       "      <td>This image shows a fork, with no person in sight.</td>\n",
       "      <td>A fork is shown in this image.</td>\n",
       "      <td>No person is present in this image.</td>\n",
       "      <td>hybrid</td>\n",
       "      <td>coco</td>\n",
       "      <td>000000397133.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  image_path  correct_answer  \\\n",
       "0  data/coco/images/val2017/000000397133.jpg               0   \n",
       "1  data/coco/images/val2017/000000397133.jpg               0   \n",
       "2  data/coco/images/val2017/000000397133.jpg               0   \n",
       "\n",
       "                                                 caption_0  \\\n",
       "0      This image features a knife, but no car is present.   \n",
       "1                    A chair is not present in this image.   \n",
       "2  A person is present in this image, but there's no fork.   \n",
       "\n",
       "                                                caption_1  \\\n",
       "0  A car is present in this image, but there is no knife.   \n",
       "1      This image shows a chair, but no spoon is present.   \n",
       "2       This image shows a fork, with no person in sight.   \n",
       "\n",
       "                           caption_2                               caption_3  \\\n",
       "0          This image features a car    This image does not feature a knife.   \n",
       "1  A chair is present in this image.  A spoon is not included in this image.   \n",
       "2     A fork is shown in this image.     No person is present in this image.   \n",
       "\n",
       "  correct_answer_template dataset_name         file_name  \n",
       "0                  hybrid         coco  000000397133.jpg  \n",
       "1                negative         coco  000000397133.jpg  \n",
       "2                  hybrid         coco  000000397133.jpg  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coco_mcq = '/Users/akanshagautam/Documents/MTech/Thesis/Dataset/NegClip/NegBench/evaluation data/images/COCO_val_mcq_llama3.1_rephrased.csv'\n",
    "voc_mcq = '/Users/akanshagautam/Documents/MTech/Thesis/Dataset/NegClip/NegBench/evaluation data/images/VOC2007_mcq_llama3.1_rephrased.csv'\n",
    "# synthetic_mcq = '/Users/akanshagautam/Documents/MTech/Thesis/Dataset/NegClip/NegBench/evaluation data/images/synthetic_mcq_llama3.1_rephrased.csv'\n",
    "msr_vtt_mcq = '/Users/akanshagautam/Documents/MTech/Thesis/Dataset/NegClip/NegBench/evaluation data/videos/msr_vtt_mcq_rephrased_llama.csv'\n",
    "\n",
    "coco_df = pd.read_csv(coco_mcq)\n",
    "voc_df = pd.read_csv(voc_mcq)\n",
    "# synthetic_df = pd.read_csv(synthetic_mcq)\n",
    "msr_vtt_df = pd.read_csv(msr_vtt_mcq)\n",
    "print(f\"COCO shape: {coco_df.shape}\")\n",
    "print(f\"VOC 2007 shape: {voc_df.shape}\")\n",
    "# print(f\"Synthetic shape: {synthetic_df.shape}\")\n",
    "print(f\"MSR VTT shape: {msr_vtt_df.shape}\")\n",
    "\n",
    "metadata_caption_df = pd.concat([coco_df, voc_df, msr_vtt_df], axis=0, ignore_index=True)\n",
    "print(f\"Final Metadata shape: {metadata_caption_df.shape}\")\n",
    "\n",
    "metadata_caption_df[['dataset_name', 'file_name']] = metadata_caption_df['image_path'].str.extract(r'data/([^/]+)/.*?/([^/]+\\.[a-z0-9]+)$')\n",
    "\n",
    "metadata_caption_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dataset_name\n",
       "coco       5914\n",
       "voc2007    5031\n",
       "video      1000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_caption_df['dataset_name'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load MCQ Dataset - Images / Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COCO shape: (5000, 3)\n",
      "Mediafire shape: (7010, 3)\n",
      "VOC shape: (4952, 3)\n",
      "Final Metadata shape: (16962, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>file_path</th>\n",
       "      <th>dataset_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000000182611.jpg</td>\n",
       "      <td>/Users/akanshagautam/Documents/MTech/Thesis/Dataset/NegClip/coco_val2017/000000182611.jpg</td>\n",
       "      <td>coco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000000335177.jpg</td>\n",
       "      <td>/Users/akanshagautam/Documents/MTech/Thesis/Dataset/NegClip/coco_val2017/000000335177.jpg</td>\n",
       "      <td>coco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000000278705.jpg</td>\n",
       "      <td>/Users/akanshagautam/Documents/MTech/Thesis/Dataset/NegClip/coco_val2017/000000278705.jpg</td>\n",
       "      <td>coco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000000463618.jpg</td>\n",
       "      <td>/Users/akanshagautam/Documents/MTech/Thesis/Dataset/NegClip/coco_val2017/000000463618.jpg</td>\n",
       "      <td>coco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000000568981.jpg</td>\n",
       "      <td>/Users/akanshagautam/Documents/MTech/Thesis/Dataset/NegClip/coco_val2017/000000568981.jpg</td>\n",
       "      <td>coco</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          file_name  \\\n",
       "0  000000182611.jpg   \n",
       "1  000000335177.jpg   \n",
       "2  000000278705.jpg   \n",
       "3  000000463618.jpg   \n",
       "4  000000568981.jpg   \n",
       "\n",
       "                                                                                   file_path  \\\n",
       "0  /Users/akanshagautam/Documents/MTech/Thesis/Dataset/NegClip/coco_val2017/000000182611.jpg   \n",
       "1  /Users/akanshagautam/Documents/MTech/Thesis/Dataset/NegClip/coco_val2017/000000335177.jpg   \n",
       "2  /Users/akanshagautam/Documents/MTech/Thesis/Dataset/NegClip/coco_val2017/000000278705.jpg   \n",
       "3  /Users/akanshagautam/Documents/MTech/Thesis/Dataset/NegClip/coco_val2017/000000463618.jpg   \n",
       "4  /Users/akanshagautam/Documents/MTech/Thesis/Dataset/NegClip/coco_val2017/000000568981.jpg   \n",
       "\n",
       "  dataset_name  \n",
       "0         coco  \n",
       "1         coco  \n",
       "2         coco  \n",
       "3         coco  \n",
       "4         coco  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coco_val_dir = '/Users/akanshagautam/Documents/MTech/Thesis/Dataset/NegClip/coco_val2017'\n",
    "mediafire_val_dir = '/Users/akanshagautam/Documents/MTech/Thesis/Dataset/NegClip/mediafire_val_videos'\n",
    "voc_val_dir = '/Users/akanshagautam/Documents/MTech/Thesis/Dataset/NegClip/VOCtest_06-Nov-2007/VOC2007/JPEGImages'\n",
    "# synthetic_mcq = '/Users/akanshagautam/Documents/MTech/Thesis/Dataset/NegClip/NegBench/evaluation data/images/synthetic_mcq_llama3.1_rephrased.csv'\n",
    "\n",
    "coco_image_files = [f for f in os.listdir(coco_val_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "mediafire_video_files = [f for f in os.listdir(mediafire_val_dir) if f.lower().endswith('.mp4')]\n",
    "voc_image_files = [f for f in os.listdir(voc_val_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n",
    "coco_val_df = pd.DataFrame({'file_name': coco_image_files, 'file_path': [os.path.join(coco_val_dir, f) for f in coco_image_files],'dataset_name': 'coco'})\n",
    "mediafire_val_df = pd.DataFrame({'file_name': mediafire_video_files, 'file_path': [os.path.join(mediafire_val_dir, f) for f in mediafire_video_files], 'dataset_name': 'video'})\n",
    "voc_val_df = pd.DataFrame({'file_name': voc_image_files, 'file_path': [os.path.join(voc_val_dir, f) for f in voc_image_files], 'dataset_name': 'voc2007'})\n",
    "\n",
    "print(f\"COCO shape: {coco_val_df.shape}\")\n",
    "print(f\"Mediafire shape: {mediafire_val_df.shape}\")\n",
    "print(f\"VOC shape: {voc_val_df.shape}\")\n",
    "\n",
    "metadata_images_videos_df = pd.concat([coco_val_df, voc_val_df, mediafire_val_df], axis=0, ignore_index=True)\n",
    "print(f\"Final Metadata shape: {metadata_images_videos_df.shape}\")\n",
    "\n",
    "metadata_images_videos_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge the captions and images/videos path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged shape: (10945, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>correct_answer</th>\n",
       "      <th>caption_0</th>\n",
       "      <th>caption_1</th>\n",
       "      <th>caption_2</th>\n",
       "      <th>caption_3</th>\n",
       "      <th>correct_answer_template</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>file_name</th>\n",
       "      <th>file_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/coco/images/val2017/000000397133.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>This image features a knife, but no car is present.</td>\n",
       "      <td>A car is present in this image, but there is no knife.</td>\n",
       "      <td>This image features a car</td>\n",
       "      <td>This image does not feature a knife.</td>\n",
       "      <td>hybrid</td>\n",
       "      <td>coco</td>\n",
       "      <td>000000397133.jpg</td>\n",
       "      <td>/Users/akanshagautam/Documents/MTech/Thesis/Dataset/NegClip/coco_val2017/000000397133.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/coco/images/val2017/000000397133.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>A chair is not present in this image.</td>\n",
       "      <td>This image shows a chair, but no spoon is present.</td>\n",
       "      <td>A chair is present in this image.</td>\n",
       "      <td>A spoon is not included in this image.</td>\n",
       "      <td>negative</td>\n",
       "      <td>coco</td>\n",
       "      <td>000000397133.jpg</td>\n",
       "      <td>/Users/akanshagautam/Documents/MTech/Thesis/Dataset/NegClip/coco_val2017/000000397133.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/coco/images/val2017/000000397133.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>A person is present in this image, but there's no fork.</td>\n",
       "      <td>This image shows a fork, with no person in sight.</td>\n",
       "      <td>A fork is shown in this image.</td>\n",
       "      <td>No person is present in this image.</td>\n",
       "      <td>hybrid</td>\n",
       "      <td>coco</td>\n",
       "      <td>000000397133.jpg</td>\n",
       "      <td>/Users/akanshagautam/Documents/MTech/Thesis/Dataset/NegClip/coco_val2017/000000397133.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/coco/images/val2017/000000397133.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>No car is present in this image.</td>\n",
       "      <td>This image features a car, but there is no spoon.</td>\n",
       "      <td>A car is present in this image.</td>\n",
       "      <td>No spoon is visible in this image.</td>\n",
       "      <td>negative</td>\n",
       "      <td>coco</td>\n",
       "      <td>000000397133.jpg</td>\n",
       "      <td>/Users/akanshagautam/Documents/MTech/Thesis/Dataset/NegClip/coco_val2017/000000397133.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/coco/images/val2017/000000397133.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>A sink and a spoon are included in this image.</td>\n",
       "      <td>A car is present in this image, but a sink is not.</td>\n",
       "      <td>This image features a car.</td>\n",
       "      <td>A sink is not present in this image.</td>\n",
       "      <td>positive</td>\n",
       "      <td>coco</td>\n",
       "      <td>000000397133.jpg</td>\n",
       "      <td>/Users/akanshagautam/Documents/MTech/Thesis/Dataset/NegClip/coco_val2017/000000397133.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  image_path  correct_answer  \\\n",
       "0  data/coco/images/val2017/000000397133.jpg               0   \n",
       "1  data/coco/images/val2017/000000397133.jpg               0   \n",
       "2  data/coco/images/val2017/000000397133.jpg               0   \n",
       "3  data/coco/images/val2017/000000397133.jpg               0   \n",
       "4  data/coco/images/val2017/000000397133.jpg               0   \n",
       "\n",
       "                                                 caption_0  \\\n",
       "0      This image features a knife, but no car is present.   \n",
       "1                    A chair is not present in this image.   \n",
       "2  A person is present in this image, but there's no fork.   \n",
       "3                         No car is present in this image.   \n",
       "4           A sink and a spoon are included in this image.   \n",
       "\n",
       "                                                caption_1  \\\n",
       "0  A car is present in this image, but there is no knife.   \n",
       "1      This image shows a chair, but no spoon is present.   \n",
       "2       This image shows a fork, with no person in sight.   \n",
       "3       This image features a car, but there is no spoon.   \n",
       "4      A car is present in this image, but a sink is not.   \n",
       "\n",
       "                           caption_2                               caption_3  \\\n",
       "0          This image features a car    This image does not feature a knife.   \n",
       "1  A chair is present in this image.  A spoon is not included in this image.   \n",
       "2     A fork is shown in this image.     No person is present in this image.   \n",
       "3    A car is present in this image.      No spoon is visible in this image.   \n",
       "4         This image features a car.    A sink is not present in this image.   \n",
       "\n",
       "  correct_answer_template dataset_name         file_name  \\\n",
       "0                  hybrid         coco  000000397133.jpg   \n",
       "1                negative         coco  000000397133.jpg   \n",
       "2                  hybrid         coco  000000397133.jpg   \n",
       "3                negative         coco  000000397133.jpg   \n",
       "4                positive         coco  000000397133.jpg   \n",
       "\n",
       "                                                                                   file_path  \n",
       "0  /Users/akanshagautam/Documents/MTech/Thesis/Dataset/NegClip/coco_val2017/000000397133.jpg  \n",
       "1  /Users/akanshagautam/Documents/MTech/Thesis/Dataset/NegClip/coco_val2017/000000397133.jpg  \n",
       "2  /Users/akanshagautam/Documents/MTech/Thesis/Dataset/NegClip/coco_val2017/000000397133.jpg  \n",
       "3  /Users/akanshagautam/Documents/MTech/Thesis/Dataset/NegClip/coco_val2017/000000397133.jpg  \n",
       "4  /Users/akanshagautam/Documents/MTech/Thesis/Dataset/NegClip/coco_val2017/000000397133.jpg  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_caption_df['dataset_name'].value_counts()\n",
    "# metadata_images_videos_df['dataset_name'].value_counts()\n",
    "\n",
    "merged_df = pd.merge(\n",
    "    metadata_caption_df,\n",
    "    metadata_images_videos_df,\n",
    "    on=['file_name', 'dataset_name'],\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "print(f\"Merged shape: {merged_df.shape}\")\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dataset_name\n",
       "coco       5914\n",
       "voc2007    5031\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df['dataset_name'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split dataset into different negation types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_caption(text):\n",
    "    if isinstance(text, str):\n",
    "        text = text.lower()\n",
    "        \n",
    "        contractions = {\n",
    "            \"isn't\": \"isnot\", \"aren't\": \"arenot\",\"wasn't\": \"wasnot\",\"weren't\": \"werenot\",\"don't\": \"donot\",\"doesn't\": \"doesnot\",\n",
    "            \"didn't\": \"didnot\",\"can't\": \"cannot\",\"couldn't\": \"couldnot\",\"won't\": \"willnot\",\"wouldn't\": \"wouldnot\",\"shouldn't\": \"shouldnot\",\n",
    "            \"mustn't\": \"mustnot\",\"hadn't\": \"hadnot\",\"hasn't\": \"hasnot\",\"haven't\": \"havenot\",\"mightn't\": \"mightnot\",\n",
    "            \"needn't\": \"neednot\",\"shan't\": \"shallnot\",\n",
    "        }\n",
    "\n",
    "        for contraction, replacement in contractions.items():\n",
    "            text = text.replace(contraction, replacement)\n",
    "\n",
    "        text = re.sub(f\"[{re.escape(string.punctuation)}]\", \" \", text)\n",
    "        text = text.strip()\n",
    "        return text\n",
    "    return text\n",
    "\n",
    "merged_df['caption_0_clean'] = merged_df['caption_0'].apply(clean_caption)\n",
    "merged_df['caption_1_clean'] = merged_df['caption_1'].apply(clean_caption)\n",
    "merged_df['caption_2_clean'] = merged_df['caption_2'].apply(clean_caption)\n",
    "merged_df['caption_3_clean'] = merged_df['caption_3'].apply(clean_caption)\n",
    "\n",
    "# merged_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>correct_answer</th>\n",
       "      <th>caption_0</th>\n",
       "      <th>caption_1</th>\n",
       "      <th>caption_2</th>\n",
       "      <th>caption_3</th>\n",
       "      <th>correct_answer_template</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>file_name</th>\n",
       "      <th>file_path</th>\n",
       "      <th>caption_0_clean</th>\n",
       "      <th>caption_1_clean</th>\n",
       "      <th>caption_2_clean</th>\n",
       "      <th>caption_3_clean</th>\n",
       "      <th>caption_0_negation_bucket</th>\n",
       "      <th>caption_1_negation_bucket</th>\n",
       "      <th>caption_2_negation_bucket</th>\n",
       "      <th>caption_3_negation_bucket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/coco/images/val2017/000000397133.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>This image features a knife, but no car is present.</td>\n",
       "      <td>A car is present in this image, but there is no knife.</td>\n",
       "      <td>This image features a car</td>\n",
       "      <td>This image does not feature a knife.</td>\n",
       "      <td>hybrid</td>\n",
       "      <td>coco</td>\n",
       "      <td>000000397133.jpg</td>\n",
       "      <td>/Users/akanshagautam/Documents/MTech/Thesis/Dataset/NegClip/coco_val2017/000000397133.jpg</td>\n",
       "      <td>this image features a knife  but no car is present</td>\n",
       "      <td>a car is present in this image  but there is no knife</td>\n",
       "      <td>this image features a car</td>\n",
       "      <td>this image does not feature a knife</td>\n",
       "      <td>syntactic</td>\n",
       "      <td>syntactic</td>\n",
       "      <td>unknown/pragmatic</td>\n",
       "      <td>syntactic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/coco/images/val2017/000000397133.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>A chair is not present in this image.</td>\n",
       "      <td>This image shows a chair, but no spoon is present.</td>\n",
       "      <td>A chair is present in this image.</td>\n",
       "      <td>A spoon is not included in this image.</td>\n",
       "      <td>negative</td>\n",
       "      <td>coco</td>\n",
       "      <td>000000397133.jpg</td>\n",
       "      <td>/Users/akanshagautam/Documents/MTech/Thesis/Dataset/NegClip/coco_val2017/000000397133.jpg</td>\n",
       "      <td>a chair is not present in this image</td>\n",
       "      <td>this image shows a chair  but no spoon is present</td>\n",
       "      <td>a chair is present in this image</td>\n",
       "      <td>a spoon is not included in this image</td>\n",
       "      <td>syntactic</td>\n",
       "      <td>syntactic</td>\n",
       "      <td>unknown/pragmatic</td>\n",
       "      <td>syntactic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/coco/images/val2017/000000397133.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>A person is present in this image, but there's no fork.</td>\n",
       "      <td>This image shows a fork, with no person in sight.</td>\n",
       "      <td>A fork is shown in this image.</td>\n",
       "      <td>No person is present in this image.</td>\n",
       "      <td>hybrid</td>\n",
       "      <td>coco</td>\n",
       "      <td>000000397133.jpg</td>\n",
       "      <td>/Users/akanshagautam/Documents/MTech/Thesis/Dataset/NegClip/coco_val2017/000000397133.jpg</td>\n",
       "      <td>a person is present in this image  but there s no fork</td>\n",
       "      <td>this image shows a fork  with no person in sight</td>\n",
       "      <td>a fork is shown in this image</td>\n",
       "      <td>no person is present in this image</td>\n",
       "      <td>syntactic</td>\n",
       "      <td>syntactic</td>\n",
       "      <td>unknown/pragmatic</td>\n",
       "      <td>syntactic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  image_path  correct_answer  \\\n",
       "0  data/coco/images/val2017/000000397133.jpg               0   \n",
       "1  data/coco/images/val2017/000000397133.jpg               0   \n",
       "2  data/coco/images/val2017/000000397133.jpg               0   \n",
       "\n",
       "                                                 caption_0  \\\n",
       "0      This image features a knife, but no car is present.   \n",
       "1                    A chair is not present in this image.   \n",
       "2  A person is present in this image, but there's no fork.   \n",
       "\n",
       "                                                caption_1  \\\n",
       "0  A car is present in this image, but there is no knife.   \n",
       "1      This image shows a chair, but no spoon is present.   \n",
       "2       This image shows a fork, with no person in sight.   \n",
       "\n",
       "                           caption_2                               caption_3  \\\n",
       "0          This image features a car    This image does not feature a knife.   \n",
       "1  A chair is present in this image.  A spoon is not included in this image.   \n",
       "2     A fork is shown in this image.     No person is present in this image.   \n",
       "\n",
       "  correct_answer_template dataset_name         file_name  \\\n",
       "0                  hybrid         coco  000000397133.jpg   \n",
       "1                negative         coco  000000397133.jpg   \n",
       "2                  hybrid         coco  000000397133.jpg   \n",
       "\n",
       "                                                                                   file_path  \\\n",
       "0  /Users/akanshagautam/Documents/MTech/Thesis/Dataset/NegClip/coco_val2017/000000397133.jpg   \n",
       "1  /Users/akanshagautam/Documents/MTech/Thesis/Dataset/NegClip/coco_val2017/000000397133.jpg   \n",
       "2  /Users/akanshagautam/Documents/MTech/Thesis/Dataset/NegClip/coco_val2017/000000397133.jpg   \n",
       "\n",
       "                                          caption_0_clean  \\\n",
       "0      this image features a knife  but no car is present   \n",
       "1                    a chair is not present in this image   \n",
       "2  a person is present in this image  but there s no fork   \n",
       "\n",
       "                                         caption_1_clean  \\\n",
       "0  a car is present in this image  but there is no knife   \n",
       "1      this image shows a chair  but no spoon is present   \n",
       "2       this image shows a fork  with no person in sight   \n",
       "\n",
       "                    caption_2_clean                        caption_3_clean  \\\n",
       "0         this image features a car    this image does not feature a knife   \n",
       "1  a chair is present in this image  a spoon is not included in this image   \n",
       "2     a fork is shown in this image     no person is present in this image   \n",
       "\n",
       "  caption_0_negation_bucket caption_1_negation_bucket  \\\n",
       "0                 syntactic                 syntactic   \n",
       "1                 syntactic                 syntactic   \n",
       "2                 syntactic                 syntactic   \n",
       "\n",
       "  caption_2_negation_bucket caption_3_negation_bucket  \n",
       "0         unknown/pragmatic                 syntactic  \n",
       "1         unknown/pragmatic                 syntactic  \n",
       "2         unknown/pragmatic                 syntactic  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syntactic_negators = {\"no\", \"not\", \"never\", \"neither\", \"nobody\", \"nothing\"}\n",
    "ignore_words = {\"image\", \"images\", \"included\", \"include\", \"includes\", \"displays\", \n",
    "\"introduces\", \"information\", \"individual\", \"individuals\", \"insert\", \"imageâ€\", \"improve\"}\n",
    "prefixes = (\"un\", \"dis\", \"in\", \"im\", \"ir\", \"il\", \"non\", \"mis\")\n",
    "lexical_negators = {\"without\", \"lack\", \"absent\", \"avoid\", \"missing\"}\n",
    "\n",
    "def is_syntactic_negation(caption):\n",
    "    tokens = caption.lower().split()\n",
    "    return any(word in syntactic_negators for word in tokens)\n",
    "\n",
    "def is_morphological_negation(caption):\n",
    "    words = caption.lower().split()\n",
    "    for word in words:\n",
    "        if word in ignore_words:\n",
    "            continue\n",
    "        if any(word.startswith(prefix) and len(word) > len(prefix) for prefix in prefixes):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def is_lexical_negation(caption):\n",
    "    tokens = caption.lower().split()\n",
    "    return any(word in lexical_negators for word in tokens)\n",
    "\n",
    "def classify_negation(caption):\n",
    "    if is_syntactic_negation(caption):\n",
    "        return \"syntactic\"\n",
    "    elif is_morphological_negation(caption):\n",
    "        return \"morphological\"\n",
    "    elif is_lexical_negation(caption):\n",
    "        return \"lexical/semantic\"\n",
    "    else:\n",
    "        return \"unknown/pragmatic\"\n",
    "    \n",
    "merged_df[\"caption_0_negation_bucket\"] = merged_df[\"caption_0_clean\"].apply(classify_negation)\n",
    "merged_df[\"caption_1_negation_bucket\"] = merged_df[\"caption_1_clean\"].apply(classify_negation)\n",
    "merged_df[\"caption_2_negation_bucket\"] = merged_df[\"caption_2_clean\"].apply(classify_negation)\n",
    "merged_df[\"caption_3_negation_bucket\"] = merged_df[\"caption_3_clean\"].apply(classify_negation)\n",
    "\n",
    "merged_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Syntactic: (10931, 18)\n",
      "Morphological: (43, 18)\n",
      "Lexical/Semantic: (814, 18)\n"
     ]
    }
   ],
   "source": [
    "# Split dataset\n",
    "negation_cols = [ 'caption_0_negation_bucket', 'caption_1_negation_bucket', 'caption_2_negation_bucket', 'caption_3_negation_bucket']\n",
    "\n",
    "syntactic_df = merged_df[merged_df[negation_cols].apply(lambda x: x.astype(str).str.contains(\"syntactic\", case=False).any(), axis=1)]\n",
    "morphological_df = merged_df[merged_df[negation_cols].apply(lambda x: x.astype(str).str.contains(\"morphological\", case=False).any(), axis=1)]\n",
    "lexical_semantic_df = merged_df[merged_df[negation_cols].apply(lambda x: x.astype(str).str.contains(\"lexical/semantic\", case=False, regex=True).any(), axis=1)]\n",
    "\n",
    "# Optional: Print counts\n",
    "print(f\"Syntactic: {syntactic_df.shape}\")\n",
    "print(f\"Morphological: {morphological_df.shape}\")\n",
    "print(f\"Lexical/Semantic: {lexical_semantic_df.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def evaluate_mcq_accuracy(df, model, processor):\n",
    "    \"\"\"\n",
    "    Evaluate multiple-choice question accuracy for negation understanding.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame with columns: 'file_path', 'caption_0', ..., 'caption_3', and 'correct_caption_index'.\n",
    "        model: Vision-language model (e.g., CLIP).\n",
    "        processor: Preprocessor for the model.\n",
    "\n",
    "    Returns:\n",
    "        results_df (pd.DataFrame): DataFrame with similarity scores and predictions.\n",
    "        accuracy (float): Accuracy of the model on the MCQ dataset.\n",
    "    \"\"\"\n",
    "    all_predictions = []\n",
    "    all_correct = []\n",
    "\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Evaluating MCQ\"):\n",
    "        image = Image.open(row[\"file_path\"]).convert(\"RGB\")\n",
    "        captions = [row[f\"caption_{i}\"] for i in range(4)]\n",
    "        correct_index = row[\"correct_caption_index\"]\n",
    "\n",
    "        # Preprocess inputs\n",
    "        inputs = processor(text=captions, images=[image]*4, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            similarities = torch.nn.functional.cosine_similarity(\n",
    "                outputs.image_embeds, outputs.text_embeds\n",
    "            )\n",
    "\n",
    "        predicted_index = similarities.argmax().item()\n",
    "        all_predictions.append(predicted_index)\n",
    "        all_correct.append(int(predicted_index == correct_index))\n",
    "\n",
    "    # Prepare results\n",
    "    results_df = df.copy()\n",
    "    results_df[\"predicted_index\"] = all_predictions\n",
    "    results_df[\"correct_prediction\"] = all_correct\n",
    "\n",
    "    # Compute accuracy\n",
    "    accuracy = sum(all_correct) / len(all_correct)\n",
    "\n",
    "    return results_df, accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load CLIP ViT Base Patch32 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[129], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m results_df, score \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_negation_sensitivity\u001b[49m\u001b[43m(\u001b[49m\u001b[43msyntactic_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocessor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mNegation Sensitivity Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscore\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m results_df\u001b[38;5;241m.\u001b[39mhead()\n",
      "Cell \u001b[0;32mIn[126], line 20\u001b[0m, in \u001b[0;36mevaluate_negation_sensitivity\u001b[0;34m(df, model, processor)\u001b[0m\n\u001b[1;32m     17\u001b[0m comparison_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Iterate through each row in the dataframe with tqdm\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, row \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterrows\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEvaluating rows\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     21\u001b[0m     image_path \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_path\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     22\u001b[0m     true_caption \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue_caption\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "results_df, score = evaluate_negation_sensitivity(syntactic_df, model, processor)\n",
    "print(f\"\\nNegation Sensitivity Score: {score:.4f}\")\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mtp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
